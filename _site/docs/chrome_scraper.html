<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>ire-toronto | Classes</title>
<meta name="generator" content="Jekyll v3.7.4" />
<meta property="og:title" content="ire-toronto" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Master github-pages for teaching" />
<meta property="og:description" content="Master github-pages for teaching" />
<link rel="canonical" href="http://localhost:4000/docs/chrome_scraper.html" />
<meta property="og:url" content="http://localhost:4000/docs/chrome_scraper.html" />
<meta property="og:site_name" content="Classes" />
<script type="application/ld+json">
{"url":"http://localhost:4000/docs/chrome_scraper.html","description":"Master github-pages for teaching","headline":"ire-toronto","@type":"WebPage","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=32d7768adcb54e7640192a0a4ddb029318967816">
    <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="http://localhost:4000/">Classes</a></h1>

        

        <p>Master github-pages for teaching</p>

        
        <p class="view"><a href="http://github.com/sarahcnyt/classes">View the Project on GitHub <small>sarahcnyt/classes</small></a></p>
        

      </header>
      <section>

      <h1 id="ire-toronto">ire-toronto</h1>
<p>Scraping may be the most valuable new skill you’ll learn this year. There are several tools out there to help you, with more coming out all the time. But at some point, if you do this enough, you’ll find that learning to program a little is a lot easier than trying to wrangle a tool into something it didn’t anticipate.</p>

<h2 id="whats-scraping-and-what-can-you-do-with-it">What’s scraping, and what can you do with it?</h2>

<p>With the simplest of tools:</p>
<ul>
  <li>Download all of the documents linked off of a page.</li>
  <li>Simple scrape of a table created on one page, like inmates at the <a href="http://showmeboone.com/sheriff/jailresidents/jailresidents.asp">Boone County jail</a> or salaries of officials in <a href="http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs.php?organization=legislative&amp;year=2013">Ontario’s legislature</a></li>
  <li>Simple scrape of a more complex page, like a page of articles from the IRE website, <a href="http://www.ire.org/blog/extra-extra/">Extra Extra</a>, or Craigslist listings for <a href="http://toronto.en.craigslist.ca/apa/">housing</a> in Toronto</li>
</ul>

<p>With some common tools:</p>
<ul>
  <li>Extract everything from a set of paginated results.</li>
  <li>Dig into detail pages when you have to click on each link on a site to get more.</li>
  <li>Simulate simple searches, like going through each possible date on the White House <a href="http://www.whitehouse.gov/schedule/complete/2013-11-04">public schedule</a>.</li>
</ul>

<p>What’s going to be hard no matter what:</p>
<ul>
  <li>Security systems that require Javascript and checking of session cookies.</li>
  <li>Search pages that require parameters you can’t know in advance</li>
  <li>Popups</li>
</ul>

<p>Most of these can be finessed with enough programming, but your simple tools probably won’t do it.</p>

<p>##Tools</p>

<p>#####Free and easy</p>

<ul>
  <li><a href="https://addons.mozilla.org/en-US/firefox/addon/downthemall/">DownloadThemAll!</a> for Firefox, <a href="https://chrome.google.com/webstore/detail/download-master/mcceagdollnkjlogmdckgjakjapmkdjf?hl=en-US">Download Master</a> for Chrome.  These will let you capture all of the files linked off a page, filtering for just the ones you want. They are great when an agency has put a whole bunch of PDFs online and you want them all in one folder so you can search them.</li>
  <li>Some people just use Google Docs for scraping simple pages, but I find them limiting and the formulas just don’t work that well.</li>
  <li><a href="https://chrome.google.com/webstore/detail/scraper/mbigbapnjcgaffohmbkdlecaccepngjd?hl=en">Chrome Scraper</a> extension, for parsing almost anything you can see on a page. Very powerful.</li>
</ul>

<p>#####Not too expensive and more powerful</p>

<ul>
  <li>Outwit Hub](http://www.outwit.com/),  US$60 - standalone software or Firefox extension that automates going through multipage results and digging into detail pages.</li>
  <li><a href="http://www.heliumscraper.com/en/index.php?p=home">Helium Scraper</a>, US$99 for Windows only. More powerful for very complicated pages, but it helps to know a little Javascript if you need to walk through forms or guess addresses.</li>
</ul>

<p>Each of these have their own odd language, so there’s a considerable learning curve. If you’re spending a lot of time learning the tool, consider putting your effort instead into learning a programming language like Ruby or Python for scraping.</p>


      </section>
      <footer>
        
        <p>This project is maintained by <a href="http://github.com/sarahcnyt">sarahcnyt</a></p>
        
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
    
  </body>
</html>
